\documentclass[12pt]{article}

\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{fancyvrb}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage[margin=1in]{geometry}
\usepackage[resetlabels,labeled]{multibib}
\usepackage{wrapfig}

\newcites{New}{The other list}

\begin{document}

\begin{wrapfigure}{r}{0.4\textwidth}
  \begin{center}
    \includegraphics[scale=0.4]{nsfpic.pdf}
  \end{center}
  \caption{\footnotesize{Blue:grid points to be calculated. Red:fixed boundary estimates}}
\end{wrapfigure}
    
    
    Consider $\bigtriangledown \epsilon \bigtriangleup u = f$, discretization by the spectral method and solved using multigrid.
    
    Discretizing the domain by the Spectral Method and solving using multigrid yields a solution with a fourier representation that is arbitrarily accurate up to k coefficients (when using, e.g. gmres to find unknowns). To get higher accuracy, one can refine the grid further. Using an initial guess for some of the unknowns from the coarse grid, low frequency errors are still small, but high frequency errors are possibly high. 
    
    Now consider the buffer zone introduced by segmental refinement, which can be represented as a new grid with two boundary conditions encoding the error by this buffer zone. The boundary will thus be functions with fourier coefficients of k or greater since the coarser grid was ~accurate up to k coefficients. 
    
    We must demonstrate that the solution to this grid with boundary values of frequency k will decay to discretization error by the time it leaves the buffer zone. On this finer grid, then, we will have error introduced by discretization of frequency 2k or higher, combined with the error that is introduced by the buffer zone and decays to discretization error. Overall, this function will still be accurate up to coefficients of 2k.
    
    Inductively, we will see that at every level of refinement, we get accuracy up to coefficients of $(2^n) k$ because at the previous level, we had $(2^{n-1}) k$ orders of accuracy.
    
    Remark: We must show that the fourier coefficients of solutions to these laplace equations decay at a certain rate in order to show that solving up to $(2^{n})$ coefficients will yield a sum that decays very quickly as we take a shorter and shorter tail of the sum. Each of the functions Sin(k x) exist on the buffer zone boundary. Assume that the boundary has finite energy, meaning it exists in $L^2$, this implies that the sum of fourier coefficients converges by Parseval's Theorem. 
    
    First, we must show that on a unit grid with one nonhomogenous boundary condition, the function decays exponentially away from the boundary. 
    
    Consider the following PDE. 
    
 \begin{gather}
\nabla^2 \Phi (x,y) = 0 \label{laplaceexstate}\\
\begin{split}
\Phi(x,0) &= 0 \quad \Phi(0,y) = 0 \\
\Phi(L,y) &= 0 \quad \Phi(x,L) = g(x). \label{laplaceexboundary}
\end{split}
\end{gather}    

Now we must apply the nonhomogeneous boundary condition $\Phi(x,1) = g(x)$ to help us find the coefficients $B_n$.
\begin{align*}
\Phi(x,y)  &= \sum_{n=1}^{\infty} B_n \sin(\frac{n\pi x}{L}) \sinh(\frac{n\pi y}{L}) \\
\end{align*}
\begin{equation}
B_n = \frac{\frac{2}{L}}{\sinh(\frac{n\pi}{L})} \int_0^1 g(x) \sin(n\pi x) \, dx
\end{equation}

\begin{align*}
\text{Let C }= max(\int_0^1 [g(x) \sin(\frac{n\pi x}{L}) \, dx]\\
\text{Let $\Phi_n(x, y)$ }=  \frac{\frac{2}{L}}{\sinh(n\pi}\int_0^1 [g(x) \sin(\frac{n\pi x}{L}) \, dx] \sin(\frac{n\pi x}{L}) \sinh(\frac{n\pi y}{L})\\
|\Phi_n(x, y)| \leq \frac{2C*sin \frac{n \pi y}{L}}{L\sinh(n\pi)} \leq \frac{2C e^{\frac{n \pi y}{L}}}{L.5*e^{n \pi}} \leq \frac{4C e^{\frac{n \pi y}{L}}}{e^{n \pi}} = \frac{4C}{L} e^\frac{{n \pi (y-L)}}{L}
\end{align*}

Let $d = L-y$ be the distance from the boundary. 

\begin{align*}
|\Phi_n(x, y)| \leq \frac{4C}{L} e^\frac{{-n \pi d}}{L} \\
|\Phi(x, y)| \leq \frac{4C * e^\frac{-n_0 \pi d}{L}}{L*(1 - e^\frac{-\pi d}{L})} < \epsilon\\
\end{align*}

\begin{align*}
d > ln(\frac{\epsilon * L(1 - e^\frac{-\pi d}{L}}{{4C}})*\frac{L}{-n_0 * \pi}\\
\text{Let L }= 2^{-k} \\
d > \frac{-ln\epsilon + kln(2) - ln(1 - e^\frac{-\pi d}{L}) - ln4C }{2^k n_0 \pi}\\
\end{align*}

This bound needs to be improved. $\frac{ln(\frac{\epsilon}{2C})}{-\pi}$ could be very large. 

We just need epsilon up to the resolution of the grid. We need to start summing at some n. This will make $d$ more reasonable. Maybe try getting $|\Phi_n| < \frac{\epsilon}{n^2}$ instead of $\epsilon^n$. Get the bound on d by biggest fourier coefficient of g and biggest fourier coefficient of forcing f. Ask Dr. Symmes if we can estimate largest fourier coefficient efficiently. 

The coarse grid has to be fine enough to make this needed $d$ reasonable, and it depends on the boundary conditions. This is the point: coarse grid must still be fine. And we can't get geometric decay. So we just want each coefficient's error to get smaller. 

Cite Marcus Mohr and Achi Brandt. Can we somehow analyze $|\Phi_n(x, y)| < \epsilon * |\Phi_n(x, y)^*|$

Ideally we'd like the sum of boundaries at each level needed to sum to some moderate amount. That way we need no communication when solving each level. 


%We can bound $|\Phi(x, y)|$ by $|\sum_{n=1}^{\infty}B_n| |\frac{e^{y}*(e^{2y} - 1)}{2}| \leq |\sum_{n=1}^{\infty}B_n | |\frac{e}{2} | |e^{2y}-1| = C|e^{2y}-1|$

%If we can want $|\Phi(x, y)| < \epsilon$

%$C|e^{2y} - 1| < \epsilon$

%$e^{2y} > 1$ because $y > 0$.

%$ e^{2y} < 1 + \frac{\epsilon}{C}$

%$(y) < \frac{ln(1+ \frac{\epsilon}{C}$

If we just need quadratic convergence, i.e. $|Phi_n(x, y)| < \frac{\epsilon}{n^2}$, then the distance requirement changes to $d \geq \frac{lnC + 2lnn - ln\epsilon}{2 \pi n}$. By choosing a sufficiently fine coarse grid, we can make this distance requirement reasonable. 



    

% \textbf{Intellectual Merit:} 
% We will find an analytical estimate for the decay of error introduced by segmental refinement as a function of wave number and strength of the boundary value perturbation. Also, we will provide a software framework for limited memory hierarchical algorithms. 
% %analytical estimate for the decay of error away from the boundary as a function of the wave number and strength of the boundary value perturbation. introduced error decays away from boundary. we will provide a software framework for limited memory hierarchical algorithms. 

% \textbf{Broader Impact:}
% A pillar of my research would be the implementation of the algorithm in open-source form such that a researcher, even one outside of the field of mathematics, could use.This would make SRMG available to experts of fields outside of mathematics without access to a computational expert as a collaborator, who still need to compute solutions to large problems. The nature of the algorithm increases the scale of problems that our strongest supercomputers can solve, as well as the scale of problems solvable on a personal computer. This makes more problems accessible to all scales of researchers, from large organizations with access to supercomputers to individual researchers without access to these resources. 

%\textbf{Need: citation that software grows quickly, flops per unknown, problems solved with multigrid, }

%Consider a laptop capable of 10^9 operations per second. An upper estimate of the computational complexity of this problem is 500 to 10^2 operations required for each unknown. Consider 10% performance of computer. 10^2*10^12 10^(9) = 10^5 = 25 hours.  

{\footnotesize
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,references}

\bibliographystyleNew{IEEEtran}
\bibliographyNew{IEEEabrv, references}
}
\end{document}


\title{Multiple Bibliographies with \texttt{multibib}}
\author{LianTze Lim}
\date{}


\usepackage[resetlabels,labeled]{multibib}

%% The new list's label is "New" and will be titled "The other list".
%% To put cites into this list, use \citeNew.
\newcites{New}{The other list}

\begin{document}

\maketitle

\cite{mydog} and \cite{url} were published later than

\bibliographystyle{plain}
\bibliography{references}

\bibliographystyleNew{plain}
\bibliographyNew{references}

\end{document}

1. Aitken's array http://oeis.org/search?q=1%2C1%2C+2%2C+2%2C+3%2C+5%2C+5&language=english&go=Search
2. https://en.wikipedia.org/wiki/Stirling%27s_approximation
3. http://ubuntuforums.org/showthread.php?t=1244186
4.It appears Newton deserves majority credit. Rhapson may have just simplified things.  It appears many people were https://en.wikipedia.org/wiki/Newton%27s_method#History
5. https://en.wikipedia.org/wiki/Leonid_Kantorovich
6. http://www.iue.tuwien.ac.at/phd/entner/node9.html
7. https://en.wikipedia.org/wiki/Special:Contributions/Jrt54 
7. https://en.wikipedia.org/w/index.php?title=Latent_semantic_indexing&diff=prev&oldid=682352132